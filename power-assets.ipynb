{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T20:48:47.673090Z",
     "iopub.status.busy": "2024-07-28T20:48:47.672233Z",
     "iopub.status.idle": "2024-07-28T20:49:54.812142Z",
     "shell.execute_reply": "2024-07-28T20:49:54.810237Z",
     "shell.execute_reply.started": "2024-07-28T20:48:47.673026Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# installing packages\n",
    "!pip install -q ultralytics\n",
    "!pip install -q scikit-learn\n",
    "!pip install -q albumentations\n",
    "!pip install -q kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T20:49:54.816378Z",
     "iopub.status.busy": "2024-07-28T20:49:54.815837Z",
     "iopub.status.idle": "2024-07-28T20:50:02.692357Z",
     "shell.execute_reply": "2024-07-28T20:50:02.690760Z",
     "shell.execute_reply.started": "2024-07-28T20:49:54.816330Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import torch\n",
    "import numpy \n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import os\n",
    "import io\n",
    "import requests\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import cv2\n",
    "import yaml\n",
    "import glob\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from albumentations import (\n",
    "    Compose, RandomRotate90, Flip, Resize,\n",
    "    RandomScale, RandomBrightnessContrast, \n",
    "    RandomGridShuffle, RandomScale, GaussNoise, \n",
    "    OneOf, CoarseDropout, RandomFog, RandomRain, \n",
    "    RandomShadow, RandomSnow, RandomSunFlare, Normalize, BboxParams\n",
    ")\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from ultralytics import YOLO\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Part 1: Merging datasets in a Folder and creating categories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T19:19:17.538090Z",
     "iopub.status.busy": "2024-07-28T19:19:17.535751Z",
     "iopub.status.idle": "2024-07-28T19:19:17.557589Z",
     "shell.execute_reply": "2024-07-28T19:19:17.556299Z",
     "shell.execute_reply.started": "2024-07-28T19:19:17.538044Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# preparing classes\n",
    "yolo_categories = {\n",
    "    \"0\": \"Yoke\",\n",
    "    \"1\": \"Yoke Suspension\",\n",
    "    \"2\": \"Spacer\",\n",
    "    \"3\": \"Damper - Stockbridge\",\n",
    "    \"4\": \"Lightning Rod Shackle\",\n",
    "    \"5\": \"Lightning Rod Suspension\",\n",
    "    \"6\": \"Polymer Insulator\",\n",
    "    \"7\": \"Glass Insulator\",\n",
    "    \"8\": \"Tower ID Plate\",\n",
    "    \"9\": \"Vari-grip\",\n",
    "    \"10\": \"Polymer Insulator Lower Shackle\",\n",
    "    \"11\": \"Polymer Insulator Upper Shackle\",\n",
    "    \"12\": \"Polymer Insulator Tower Shackle\",\n",
    "    \"13\": \"Glass Insulator Big Shankle\",\n",
    "    \"14\": \"Glass Insulator Small Shankle\",\n",
    "    \"15\": \"Glass Insulator Tower Shankle\",\n",
    "    \"16\": \"Damper - Spiral\",\n",
    "    \"17\": \"Sphere\",\n",
    "    \"18\": \"Cable\",\n",
    "    \"19\": \"Fuse Cutout - Closed\",\n",
    "    \"20\": \"Broken Cable\",\n",
    "    \"21\": \"Tower\",\n",
    "    \"22\": \"Broken Polymer-insulator\",\n",
    "    \"23\": \"Vegetation\",\n",
    "    \"24\": \"Transformer\",\n",
    "    \"25\": \"Connector\",\n",
    "    \"26\": \"Overhead Switch\",\n",
    "    \"27\": \"Broken Vari-Grip\",\n",
    "    \"28\": \"Broken Polymer Insulator Upper Shackle\",\n",
    "    \"29\": \"Broken Glass Insulator\",\n",
    "    \"30\": \"Broken Lightning Rod suspension\",\n",
    "    \"31\": \"Broken Yoke Suspension\",\n",
    "    \"32\": \"Bird Nest\",\n",
    "    \"33\": \"ALS\",\n",
    "    \"34\": \"Damaged ALS\",\n",
    "    \"35\": \"Fuse Cutout - Open\",\n",
    "    \"36\": \"Surge Arrester\",\n",
    "    \"37\": \"Broken-Damper-Stockbridge\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Augmentation of Images and Creating Train, Validation, Test Dataset for Yolo training.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T18:46:39.463463Z",
     "iopub.status.busy": "2024-07-28T18:46:39.463032Z",
     "iopub.status.idle": "2024-07-28T18:46:40.200215Z",
     "shell.execute_reply": "2024-07-28T18:46:40.198779Z",
     "shell.execute_reply.started": "2024-07-28T18:46:39.463430Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "images_dataset = os.listdir(\"/kaggle/input/power-line-assets-version-2/Power Line Assets Images\")\n",
    "labels_dataset = os.listdir(\"/kaggle/input/power-line-assets-version-2/Power Line Assets Labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T18:46:40.202430Z",
     "iopub.status.busy": "2024-07-28T18:46:40.201891Z",
     "iopub.status.idle": "2024-07-28T18:46:40.210915Z",
     "shell.execute_reply": "2024-07-28T18:46:40.209532Z",
     "shell.execute_reply.started": "2024-07-28T18:46:40.202382Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21652 21652\n"
     ]
    }
   ],
   "source": [
    "print(len(images_dataset), len(labels_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T19:20:43.035815Z",
     "iopub.status.busy": "2024-07-28T19:20:43.035298Z",
     "iopub.status.idle": "2024-07-28T19:41:37.089919Z",
     "shell.execute_reply": "2024-07-28T19:41:37.088217Z",
     "shell.execute_reply.started": "2024-07-28T19:20:43.035776Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "def read_bboxes_from_txt(txt_path, img_width, img_height):\n",
    "    with open(txt_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    bboxes = []\n",
    "    class_labels = []\n",
    "    format_is_yolo = True\n",
    "    \n",
    "    for line in lines:\n",
    "        # Check if the coordinates are in YOLO format by checking if they are in the range [0, 1]\n",
    "        coords = list(map(float, line.strip().split()[1:]))\n",
    "        if any(coord > 1.0 for coord in coords):\n",
    "            format_is_yolo = False\n",
    "            break\n",
    "    \n",
    "    if format_is_yolo:\n",
    "        for line in lines:\n",
    "            cls, cx, cy, w, h = map(float, line.strip().split())\n",
    "            bboxes.append([cx, cy, w, h])\n",
    "            class_labels.append(cls)\n",
    "    else:\n",
    "        for line in lines:\n",
    "            cls, x_min, y_min, x_max, y_max = map(float, line.strip().split())\n",
    "            # Convert to YOLO format\n",
    "            cx = (x_min + x_max) / 2.0\n",
    "            cy = (y_min + y_max) / 2.0\n",
    "            w = x_max - x_min\n",
    "            h = y_max - y_min\n",
    "            # Normalize coordinates\n",
    "            cx /= img_width\n",
    "            cy /= img_height\n",
    "            w /= img_width\n",
    "            h /= img_height\n",
    "            bboxes.append([cx, cy, w, h])\n",
    "            class_labels.append(cls)\n",
    "    \n",
    "    return bboxes, class_labels\n",
    "\n",
    "def save_bboxes_to_txt(bboxes, class_labels, txt_path):\n",
    "    with open(txt_path, 'w') as file:\n",
    "        for bbox, cls in zip(bboxes, class_labels):\n",
    "            x, y, w, h = bbox\n",
    "            file.write(f\"{str(int(cls))} {x} {y} {w} {h}\\n\")\n",
    "                  \n",
    "transform2 = Compose([\n",
    "    Resize(width=640, height=640), \n",
    "    RandomRotate90(p=0.5),\n",
    "    Flip(p=0.5),\n",
    "    RandomBrightnessContrast(p=0.5, brightness_limit=0.1, contrast_limit=0.1),\n",
    "    RandomScale(p=0.5, scale_limit=(0.8, 1.2)),\n",
    "    GaussNoise(p=0.5, var_limit=(10.0, 50.0)),\n",
    "    OneOf([\n",
    "        RandomRain(p=0.5, brightness_coefficient=0.9),\n",
    "        RandomFog(p=0.5, fog_coef_lower=0.01, fog_coef_upper=0.1, alpha_coef=0.1),\n",
    "        RandomSnow(p=0.5, snow_point_lower=0.1, snow_point_upper=0.3, brightness_coeff=1.2),\n",
    "        RandomShadow(p=0.5, shadow_dimension=3, num_shadows_lower=1, num_shadows_upper=2, shadow_roi=(0, 0.5, 1, 1))\n",
    "    ], p=0.5),\n",
    "    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "], bbox_params=BboxParams(format=\"yolo\", min_visibility=0.1, label_fields=['class_labels']))\n",
    "\n",
    "def apply_aug2(image, bboxes, class_labels, tran):\n",
    "    augmented = tran(image=image, bboxes=bboxes, class_labels=class_labels)\n",
    "    return augmented['image'], augmented['bboxes'], augmented['class_labels']\n",
    "\n",
    "\n",
    "\n",
    "def process_image(img_names, image_dir, labels_dir, outputimg, outputtxt, tran, target_list, augment_times):\n",
    "    for img_name in img_names:\n",
    "        name = img_name.split(\".jpg\")[0]\n",
    "        img_path = os.path.join(image_dir, img_name)\n",
    "        bboxes_path = os.path.join(labels_dir, name + \".txt\")\n",
    "        \n",
    "        if os.path.exists(bboxes_path):\n",
    "            image = cv2.imread(img_path)\n",
    "            img_height, img_width = image.shape[:2]\n",
    "            bboxes, class_labels = read_bboxes_from_txt(bboxes_path, img_width, img_height)\n",
    "\n",
    "            try:\n",
    "                augment_count = augment_times if any(cls in target_list for cls in class_labels) else 1\n",
    "                for at in range(augment_count):\n",
    "                    augmented_image, augmented_bboxes, augmented_class_labels = apply_aug2(image, bboxes, class_labels, tran)\n",
    "                    if augmented_bboxes:\n",
    "                        output_aug_img_path = os.path.join(outputimg, f\"aug_{at}-{name}.jpg\")\n",
    "                        output_aug_txt_path = os.path.join(outputtxt, f\"aug_{at}-{name}.txt\")\n",
    "                        cv2.imwrite(output_aug_img_path, augmented_image)\n",
    "                        save_bboxes_to_txt(augmented_bboxes, augmented_class_labels, output_aug_txt_path)\n",
    "            except Exception as e:\n",
    "                print(bboxes_path, img_name, class_labels)\n",
    "\n",
    "def process_images_in_batches(img_names, image_dir, labels_dir, outputimg, outputtxt, tran, target_list, augment_times, batch_size=16):\n",
    "    os.makedirs(outputimg, exist_ok=True)\n",
    "    os.makedirs(outputtxt, exist_ok=True)\n",
    "\n",
    "    for i in range(0, len(img_names), batch_size):\n",
    "        batch = img_names[i:i + batch_size]\n",
    "        process_image(batch, image_dir, labels_dir, outputimg, outputtxt, tran, target_list, augment_times)\n",
    "            \n",
    "\n",
    "target_list = [2, 4, 12, 11, 10, 17, 18, 20, 23, 21, 37, 35]\n",
    "augmented_times = 4\n",
    "            \n",
    "            \n",
    "# image_dir = \"/kaggle/working/power_assets/images/train\"\n",
    "# labels_dir = \"/kaggle/working/power_assets/labels/train\"\n",
    "image_dir = \"/kaggle/input/power-line-assets-editedv2-trainaug/images/valid\"\n",
    "labels_dir = \"/kaggle/input/power-line-assets-editedv2-trainaug/labels/valid\"\n",
    "output_dir_img = \"/kaggle/working/Augmented_images_val\"\n",
    "output_dir_txt = \"/kaggle/working/Augmented_texts_val\"\n",
    "\n",
    "img_names = os.listdir(image_dir)\n",
    "process_images_in_batches(img_names, image_dir, labels_dir, output_dir_img, output_dir_txt, transform2, target_list, augmented_times, batch_size=1024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T18:46:40.213505Z",
     "iopub.status.busy": "2024-07-28T18:46:40.212789Z",
     "iopub.status.idle": "2024-07-28T18:46:40.231831Z",
     "shell.execute_reply": "2024-07-28T18:46:40.230231Z",
     "shell.execute_reply.started": "2024-07-28T18:46:40.213448Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Sorted Power Assets\n",
    "# preparing dataset for yolo\n",
    "os.mkdir(\"/kaggle/working/power_assets\")\n",
    "os.mkdir(\"/kaggle/working/power_assets/images\")\n",
    "os.mkdir(\"/kaggle/working/power_assets/labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T18:46:40.234363Z",
     "iopub.status.busy": "2024-07-28T18:46:40.233723Z",
     "iopub.status.idle": "2024-07-28T18:46:40.267120Z",
     "shell.execute_reply": "2024-07-28T18:46:40.265622Z",
     "shell.execute_reply.started": "2024-07-28T18:46:40.234320Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "def read_bboxes_from_txt(txt_path, img_width, img_height):\n",
    "    with open(txt_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    bboxes = []\n",
    "    class_labels = []\n",
    "    format_is_yolo = True\n",
    "    \n",
    "    for line in lines:\n",
    "        # Check if the coordinates are in YOLO format by checking if they are in the range [0, 1]\n",
    "        coords = list(map(float, line.strip().split()[1:]))\n",
    "        if any(coord > 1.0 for coord in coords):\n",
    "            format_is_yolo = False\n",
    "            break\n",
    "    \n",
    "    if format_is_yolo:\n",
    "        for line in lines:\n",
    "            cls, cx, cy, w, h = map(float, line.strip().split())\n",
    "            bboxes.append([cx, cy, w, h])\n",
    "            class_labels.append(cls)\n",
    "    else:\n",
    "        for line in lines:\n",
    "            cls, x_min, y_min, x_max, y_max = map(float, line.strip().split())\n",
    "            # Convert to YOLO format\n",
    "            cx = (x_min + x_max) / 2.0\n",
    "            cy = (y_min + y_max) / 2.0\n",
    "            w = x_max - x_min\n",
    "            h = y_max - y_min\n",
    "            # Normalize coordinates\n",
    "            cx /= img_width\n",
    "            cy /= img_height\n",
    "            w /= img_width\n",
    "            h /= img_height\n",
    "            bboxes.append([cx, cy, w, h])\n",
    "            class_labels.append(cls)\n",
    "    \n",
    "    return bboxes, class_labels\n",
    "\n",
    "def save_bboxes_to_txt(bboxes, class_labels, txt_path):\n",
    "    with open(txt_path, 'w') as file:\n",
    "        for bbox, cls in zip(bboxes, class_labels):\n",
    "            x, y, w, h = bbox\n",
    "            file.write(f\"{str(int(cls))} {x} {y} {w} {h}\\n\")\n",
    "            \n",
    "transform1 = Compose([\n",
    "    Resize(width=640, height=640),\n",
    "], bbox_params=BboxParams(format=\"yolo\", min_visibility=0.1, label_fields=['class_labels']))\n",
    "           \n",
    "def apply_aug2(image, bboxes, class_labels, tran):\n",
    "    augmented = tran(image=image, bboxes=bboxes, class_labels=class_labels)\n",
    "    return augmented['image'], augmented['bboxes'], augmented['class_labels']\n",
    "\n",
    "\n",
    "\n",
    "def process_image(img_names, image_dir, labels_dir, outputimg, outputtxt, tran):\n",
    "    for img_name in img_names:\n",
    "        name = img_name.split(\".jpg\")[0]\n",
    "        img_path = os.path.join(image_dir, img_name)\n",
    "        bboxes_path = os.path.join(labels_dir, name + \".txt\")\n",
    "        \n",
    "        if os.path.exists(bboxes_path):\n",
    "            image = cv2.imread(img_path)\n",
    "            img_height, img_width = image.shape[:2]\n",
    "            bboxes, class_labels = read_bboxes_from_txt(bboxes_path, img_width, img_height)\n",
    "\n",
    "            try:\n",
    "                augmented_image, augmented_bboxes, augmented_class_labels = apply_aug2(image, bboxes, class_labels, tran)\n",
    "                if augmented_bboxes:\n",
    "                    output_aug_img_path = os.path.join(outputimg, f\"aug-{name}.jpg\")\n",
    "                    output_aug_txt_path = os.path.join(outputtxt, f\"aug-{name}.txt\")\n",
    "                    cv2.imwrite(output_aug_img_path, augmented_image)\n",
    "                    save_bboxes_to_txt(augmented_bboxes, augmented_class_labels, output_aug_txt_path)\n",
    "            except Exception as e:\n",
    "                print(bboxes_path, img_name, class_labels)\n",
    "\n",
    "def process_images_in_batches2(img_names, image_dir, labels_dir, outputimg, outputtxt, tran, batch_size=16):\n",
    "    os.makedirs(outputimg, exist_ok=True)\n",
    "    os.makedirs(outputtxt, exist_ok=True)\n",
    "\n",
    "    for i in range(0, len(img_names), batch_size):\n",
    "        batch = img_names[i:i + batch_size]\n",
    "        process_image(batch, image_dir, labels_dir, outputimg, outputtxt, tran)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T18:46:40.270597Z",
     "iopub.status.busy": "2024-07-28T18:46:40.269177Z",
     "iopub.status.idle": "2024-07-28T19:00:01.876801Z",
     "shell.execute_reply": "2024-07-28T19:00:01.873266Z",
     "shell.execute_reply.started": "2024-07-28T18:46:40.270548Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/DSC_0933_JPG_jpg.rf.bf77cd6de60a69b5b52b7505685f0fc7.txt DSC_0933_JPG_jpg.rf.bf77cd6de60a69b5b52b7505685f0fc7.jpg [6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/313-2_DJI_0298_jpg.rf.a3c5a462c316a5297633fb6c2dddffe0.txt 313-2_DJI_0298_jpg.rf.a3c5a462c316a5297633fb6c2dddffe0.jpg [6.0, 6.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 0.0, 1.0, 16.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 16.0, 16.0, 16.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/8545245_png.rf.f9dd7f199be684b1aff03bb32a32467a.txt 8545245_png.rf.f9dd7f199be684b1aff03bb32a32467a.jpg [23.0, 23.0, 23.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/240-1_DJI_0123_jpg.rf.c5df14693b370fa7fd404216150a03f1.txt 240-1_DJI_0123_jpg.rf.c5df14693b370fa7fd404216150a03f1.jpg [5.0, 25.0, 3.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/292-1_DJI_0156_jpg.rf.c02d3739888fa8ffbe6a9c05f0d2b567.txt 292-1_DJI_0156_jpg.rf.c02d3739888fa8ffbe6a9c05f0d2b567.jpg [10.0, 7.0, 13.0, 7.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/239-1_DJI_0226_jpg.rf.7fd82ea1a6ede19f0c0311905a998f77.txt 239-1_DJI_0226_jpg.rf.7fd82ea1a6ede19f0c0311905a998f77.jpg [5.0, 25.0, 3.0, 3.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/telechargement-51-_jpg.rf.a3c02829e4883f29927a48be01689358.txt telechargement-51-_jpg.rf.a3c02829e4883f29927a48be01689358.jpg [36.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/130019v_jpg.rf.796596a6eafa6db39db2ff98f8dad719.txt 130019v_jpg.rf.796596a6eafa6db39db2ff98f8dad719.jpg [6.0, 6.0, 22.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/309-1_DJI_0018_jpg.rf.913206e0fdf85f6dc90ca256890d3113.txt 309-1_DJI_0018_jpg.rf.913206e0fdf85f6dc90ca256890d3113.jpg [16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 1.0, 1.0, 1.0, 0.0, 16.0, 16.0, 16.0, 16.0, 16.0, 1.0, 16.0, 16.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/VI6_HI0_CO0_FC0_OS0_TF0_0_HBD_127_jpg.rf.30d6ccf9de7bb5bc8628f91ec4e753ff.txt VI6_HI0_CO0_FC0_OS0_TF0_0_HBD_127_jpg.rf.30d6ccf9de7bb5bc8628f91ec4e753ff.jpg [6.0, 6.0, 6.0, 6.0, 6.0, 6.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/Fotos-16-12-2020_DJI_0110_vari_grip_468_jpg.rf.a6ea64151257153a59f6822e8f98e9d6.txt Fotos-16-12-2020_DJI_0110_vari_grip_468_jpg.rf.a6ea64151257153a59f6822e8f98e9d6.jpg [9.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/09-06-2021_DJI_0467_570_7_jpg.rf.5058b221dbc877e06fd7123e82bc0a02.txt 09-06-2021_DJI_0467_570_7_jpg.rf.5058b221dbc877e06fd7123e82bc0a02.jpg [27.0, 16.0, 21.0, 8.0, 16.0, 16.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/238-2_DJI_0301_jpg.rf.875ee32c2735333ef76f9139ac006d0c.txt 238-2_DJI_0301_jpg.rf.875ee32c2735333ef76f9139ac006d0c.jpg [5.0, 25.0, 3.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/276-1_DJI_0540_jpg.rf.0bbd65983ca8c8729983af35dd010286.txt 276-1_DJI_0540_jpg.rf.0bbd65983ca8c8729983af35dd010286.jpg [16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 1.0, 0.0, 1.0, 1.0, 7.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/314-1_DJI_0256_jpg.rf.4b208482c4b43a5051db25aa35d274c6.txt 314-1_DJI_0256_jpg.rf.4b208482c4b43a5051db25aa35d274c6.jpg [16.0, 16.0, 6.0, 1.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 1.0, 11.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/VI3_HI0_CO0_FC0_OS0_TF0_0_HBD_136_jpg.rf.548b9bab8f8591b2caf71e8a408e10f5.txt VI3_HI0_CO0_FC0_OS0_TF0_0_HBD_136_jpg.rf.548b9bab8f8591b2caf71e8a408e10f5.jpg [6.0, 6.0, 6.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/DJI_20230609090407_0008_Z_JPG.rf.f367eebac2f8390e8b1d624167855126.txt DJI_20230609090407_0008_Z_JPG.rf.f367eebac2f8390e8b1d624167855126.jpg [32.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/310-2_DJI_0186_jpg.rf.b0414aa5bc06c77c0fb55ee60e0476b8.txt 310-2_DJI_0186_jpg.rf.b0414aa5bc06c77c0fb55ee60e0476b8.jpg [6.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 6.0, 6.0, 1.0, 1.0, 0.0, 1.0, 1.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/241-3_DJI_0475_jpg.rf.b1a3d13e1d4e9862d92007645a1cead6.txt 241-3_DJI_0475_jpg.rf.b1a3d13e1d4e9862d92007645a1cead6.jpg [0.0, 1.0, 1.0, 1.0, 10.0, 10.0, 1.0, 16.0, 6.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/335-1_DJI_0018_jpg.rf.59241d7590e4bee678f256840b5271fe.txt 335-1_DJI_0018_jpg.rf.59241d7590e4bee678f256840b5271fe.jpg [13.0, 2.0, 7.0, 2.0, 7.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/241-3_DJI_0517_jpg.rf.3f465172846eac67267c537e007d61dc.txt 241-3_DJI_0517_jpg.rf.3f465172846eac67267c537e007d61dc.jpg [6.0, 6.0, 6.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/170651d_JPG.rf.ee11936d5f049541ddb2cde5b4a7757d.txt 170651d_JPG.rf.ee11936d5f049541ddb2cde5b4a7757d.jpg [22.0, 3.0, 3.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/VI3_HI0_CO0_FC3_OS0_TF1_0_20210130_VH_182_JPG_jpg.rf.4cb2335dd29601c500454b25cb60ae8f.txt VI3_HI0_CO0_FC3_OS0_TF1_0_20210130_VH_182_JPG_jpg.rf.4cb2335dd29601c500454b25cb60ae8f.jpg [6.0, 6.0, 6.0, 19.0, 19.0, 19.0, 24.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/Fotos-01-12-2020_DJI_0026_manilha_isolador_superior_121_jpg.rf.c88de3f4f00e15ac9894767d6e132674.txt Fotos-01-12-2020_DJI_0026_manilha_isolador_superior_121_jpg.rf.c88de3f4f00e15ac9894767d6e132674.jpg [11.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/252-1_DJI_0154_jpg.rf.17ea22fc49fc05cf702c950af7e2458b.txt 252-1_DJI_0154_jpg.rf.17ea22fc49fc05cf702c950af7e2458b.jpg [1.0, 1.0, 1.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 6.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/02-06-2021_DJI_0408_266_1_jpg.rf.68d95cab3c7646dab7060e2c836800b9.txt 02-06-2021_DJI_0408_266_1_jpg.rf.68d95cab3c7646dab7060e2c836800b9.jpg [11.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/9L-561-TX-Post-Top-INs-Looked-Discoloured_JPG.rf.0f471ce04282994824c7470a0b6dda3b.txt 9L-561-TX-Post-Top-INs-Looked-Discoloured_JPG.rf.0f471ce04282994824c7470a0b6dda3b.jpg [6.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/Fotos-14-12-2020_DJI_0726_amarra_balancim_2444_jpg.rf.d14029c18e47cb0e5c54b46ddbdef7bf.txt Fotos-14-12-2020_DJI_0726_amarra_balancim_2444_jpg.rf.d14029c18e47cb0e5c54b46ddbdef7bf.jpg [1.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/308-2_DJI_0096_jpg.rf.05b41ccb0843aa2d5c9b38a0491d3609.txt 308-2_DJI_0096_jpg.rf.05b41ccb0843aa2d5c9b38a0491d3609.jpg [16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 1.0, 1.0, 1.0, 0.0, 6.0, 1.0, 16.0, 16.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/Fotos-26-11-2020_DJI_0355_amarra_balancim_5725_jpg.rf.1ffb4eeb3e6d5c5bbf3bbec6189facf7.txt Fotos-26-11-2020_DJI_0355_amarra_balancim_5725_jpg.rf.1ffb4eeb3e6d5c5bbf3bbec6189facf7.jpg [1.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/Fotos-08-12-2020_DJI_0754_suspensao_para_raio_111_jpg.rf.dcc46791a40cdc04867360ed679a199e.txt Fotos-08-12-2020_DJI_0754_suspensao_para_raio_111_jpg.rf.dcc46791a40cdc04867360ed679a199e.jpg [5.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/150454v_JPG.rf.f2c5d5f2f79e419404f61898a6cc1ea2.txt 150454v_JPG.rf.f2c5d5f2f79e419404f61898a6cc1ea2.jpg [6.0, 22.0, 6.0, 3.0, 5.0, 5.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/Fotos-30-11-2020_DJI_0247_amarra_balancim_6429_jpg.rf.d0b76f943c3d315e84eecee00824d5ef.txt Fotos-30-11-2020_DJI_0247_amarra_balancim_6429_jpg.rf.d0b76f943c3d315e84eecee00824d5ef.jpg [1.0, 7.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/241-3_DJI_0518_jpg.rf.56e2e1f1a5e33f297001e8a2cfe773e0.txt 241-3_DJI_0518_jpg.rf.56e2e1f1a5e33f297001e8a2cfe773e0.jpg [6.0, 1.0, 6.0, 1.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/256-1_DJI_0178_jpg.rf.de2a00a215b0730f67f34c5169793303.txt 256-1_DJI_0178_jpg.rf.de2a00a215b0730f67f34c5169793303.jpg [10.0, 1.0, 1.0, 0.0, 6.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/314-1_DJI_0250_jpg.rf.b17ce5b263eda3afbe21841c00f8bd69.txt 314-1_DJI_0250_jpg.rf.b17ce5b263eda3afbe21841c00f8bd69.jpg [0.0, 16.0, 16.0, 16.0, 1.0, 1.0, 1.0, 10.0, 16.0, 16.0, 6.0, 16.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/334-2_DJI_0481_jpg.rf.4940624bbd8ad77d6c610b60c7df3b15.txt 334-2_DJI_0481_jpg.rf.4940624bbd8ad77d6c610b60c7df3b15.jpg [7.0, 7.0, 13.0, 13.0, 15.0, 14.0, 14.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/Fotos-22-10-2020_DJI_0747_suspensao_para_raio_548_jpg.rf.a74c94839f43f6dac47aca8a2e34098f.txt Fotos-22-10-2020_DJI_0747_suspensao_para_raio_548_jpg.rf.a74c94839f43f6dac47aca8a2e34098f.jpg [5.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/239-1_DJI_0270_jpg.rf.e11c95f5165bf0fbfbc0a95388d407c0.txt 239-1_DJI_0270_jpg.rf.e11c95f5165bf0fbfbc0a95388d407c0.jpg [0.0, 1.0, 1.0, 6.0, 10.0, 16.0, 16.0, 16.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/241-3_DJI_0519_jpg.rf.e4577c8fd8d4e8a6fb4b8f9b4abde7fa.txt 241-3_DJI_0519_jpg.rf.e4577c8fd8d4e8a6fb4b8f9b4abde7fa.jpg [1.0, 1.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/VI3_HI0_CO0_FC3_OS0_TF1_0_HBD_046_jpg.rf.ed104eb81d7752085dbd8883d1422f42.txt VI3_HI0_CO0_FC3_OS0_TF1_0_HBD_046_jpg.rf.ed104eb81d7752085dbd8883d1422f42.jpg [6.0, 6.0, 6.0, 19.0, 19.0, 19.0, 24.0, 25.0, 25.0, 25.0, 6.0, 6.0, 6.0, 6.0, 6.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/Fotos-20-11-2020_DJI_0288_amarra_balancim_4120_jpg.rf.eac63f7a5ed11f5919414168caff726f.txt Fotos-20-11-2020_DJI_0288_amarra_balancim_4120_jpg.rf.eac63f7a5ed11f5919414168caff726f.jpg [1.0, 3.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/317-2_DJI_0007_jpg.rf.b72add3abe365a3e47a97b009f82d5ce.txt 317-2_DJI_0007_jpg.rf.b72add3abe365a3e47a97b009f82d5ce.jpg [6.0, 9.0, 9.0, 1.0, 1.0, 0.0, 10.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/VI0_HI9_CO2_FC0_OS6_TF0_0_HBD_176_jpg.rf.9cddea4f7d133bf9a46d63a3ba056a1b.txt VI0_HI9_CO2_FC0_OS6_TF0_0_HBD_176_jpg.rf.9cddea4f7d133bf9a46d63a3ba056a1b.jpg [6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 25.0, 25.0, 25.0, 25.0, 25.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/VI3_HI3_CO6_FC0_OS0_TF0_0_HBD_115_jpg.rf.0e2bffc20b07b04aae250518b9d17561.txt VI3_HI3_CO6_FC0_OS0_TF0_0_HBD_115_jpg.rf.0e2bffc20b07b04aae250518b9d17561.jpg [7.0, 7.0, 7.0, 25.0, 25.0, 25.0, 7.0, 7.0, 7.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/VI3_HI0_CO2_FC3_OS0_TF1_0_20210130_VH_190_JPG_jpg.rf.0e7a4c39e9314101f405435c39bb125e.txt VI3_HI0_CO2_FC3_OS0_TF1_0_20210130_VH_190_JPG_jpg.rf.0e7a4c39e9314101f405435c39bb125e.jpg [6.0, 6.0, 6.0, 19.0, 19.0, 19.0, 24.0, 25.0, 25.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/308-2_DJI_0076_jpg.rf.681c7fea196fac09e7b2c9f1237b48e1.txt 308-2_DJI_0076_jpg.rf.681c7fea196fac09e7b2c9f1237b48e1.jpg [21.0, 6.0, 6.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 6.0, 1.0, 0.0, 1.0, 11.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/VI3_HI0_CO0_FC3_OS0_TF1_0_20210130_VH_184_JPG_jpg.rf.135a22e664fcecbeeee663c5f2c0a122.txt VI3_HI0_CO0_FC3_OS0_TF1_0_20210130_VH_184_JPG_jpg.rf.135a22e664fcecbeeee663c5f2c0a122.jpg [24.0, 19.0, 19.0, 19.0, 6.0, 6.0, 6.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/VI3_HI0_CO3_FC3_OS0_TF1_0_20210130_VH_105_JPG_jpg.rf.5ed4a36a551d2051eab09d6a05a7e3ec.txt VI3_HI0_CO3_FC3_OS0_TF1_0_20210130_VH_105_JPG_jpg.rf.5ed4a36a551d2051eab09d6a05a7e3ec.jpg [6.0, 6.0, 6.0, 19.0, 19.0, 19.0, 24.0, 25.0, 25.0, 25.0, 36.0, 36.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/10-06-2021_DJI_0018_611_jpg.rf.97ffb6611eb5ff49036608755fe16ab9.txt 10-06-2021_DJI_0018_611_jpg.rf.97ffb6611eb5ff49036608755fe16ab9.jpg [27.0, 23.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/VI3_HI0_CO0_FC0_OS0_TF0_0_HBD_052_jpg.rf.8b31bd20f743addd75c45bf9a3a4738d.txt VI3_HI0_CO0_FC0_OS0_TF0_0_HBD_052_jpg.rf.8b31bd20f743addd75c45bf9a3a4738d.jpg [7.0, 7.0, 7.0, 6.0, 6.0, 6.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/VI3_HI0_CO0_FC3_OS0_TF1_0_HBD_169_jpg.rf.92a2bd036b964518dea0c7f2c05b495f.txt VI3_HI0_CO0_FC3_OS0_TF1_0_HBD_169_jpg.rf.92a2bd036b964518dea0c7f2c05b495f.jpg [6.0, 6.0, 6.0, 19.0, 19.0, 19.0, 24.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/02-06-2021_DJI_0091_202_0_jpg.rf.4d32634774ca124b97225e46593a6a38.txt 02-06-2021_DJI_0091_202_0_jpg.rf.4d32634774ca124b97225e46593a6a38.jpg [31.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/Fotos-01-12-2020_DJI_0249_amarra_balancim_267_jpg.rf.dbca3444fc01b0130951194204c7f88b.txt Fotos-01-12-2020_DJI_0249_amarra_balancim_267_jpg.rf.dbca3444fc01b0130951194204c7f88b.jpg [1.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/Fotos-16-12-2020_DJI_0349_amarra_balancim_3035_jpg.rf.c3f1a23d6b4cc134df55a7ff955b12fd.txt Fotos-16-12-2020_DJI_0349_amarra_balancim_3035_jpg.rf.c3f1a23d6b4cc134df55a7ff955b12fd.jpg [1.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/VI3_HI0_CO0_FC3_OS0_TF1_0_20210130_VH_114_JPG_jpg.rf.4b1cbefb843abf1b13124a93ce1adfc1.txt VI3_HI0_CO0_FC3_OS0_TF1_0_20210130_VH_114_JPG_jpg.rf.4b1cbefb843abf1b13124a93ce1adfc1.jpg [19.0, 19.0, 19.0, 6.0, 6.0, 36.0, 6.0, 24.0, 36.0, 36.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/302-1_DJI_0380_jpg.rf.cbe4066e118523eeef9fa63979a0a210.txt 302-1_DJI_0380_jpg.rf.cbe4066e118523eeef9fa63979a0a210.jpg [7.0, 7.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/VI3_HI0_CO0_FC3_OS0_TF1_0_20210203_LP_118_jpg.rf.f51ac27bcada5dfa1ec002d8261bb265.txt VI3_HI0_CO0_FC3_OS0_TF1_0_20210203_LP_118_jpg.rf.f51ac27bcada5dfa1ec002d8261bb265.jpg [6.0, 6.0, 36.0, 6.0, 19.0, 19.0, 19.0, 24.0, 36.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/VI3_HI0_CO0_FC3_OS0_TF1_0_20210114_MBS_111_jpg.rf.40388fb1beab38430b2bc0a21ac31620.txt VI3_HI0_CO0_FC3_OS0_TF1_0_20210114_MBS_111_jpg.rf.40388fb1beab38430b2bc0a21ac31620.jpg [6.0, 6.0, 6.0, 19.0, 19.0, 19.0, 24.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/150599-2-d_JPG.rf.9ab62d596290b39f5407dcc96006fd0e.txt 150599-2-d_JPG.rf.9ab62d596290b39f5407dcc96006fd0e.jpg [6.0, 22.0, 6.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/302-1_DJI_0358_jpg.rf.030ea6a6ba5d834985d98416ae337ba2.txt 302-1_DJI_0358_jpg.rf.030ea6a6ba5d834985d98416ae337ba2.jpg [11.0, 7.0, 7.0, 16.0, 16.0, 16.0, 15.0, 14.0, 7.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/277-2_DJI_0298_jpg.rf.b6b7889c6daeaecc8268d0a8bfc5fdbc.txt 277-2_DJI_0298_jpg.rf.b6b7889c6daeaecc8268d0a8bfc5fdbc.jpg [7.0, 14.0, 15.0, 15.0, 32.0, 7.0, 7.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/CT-2_DJI_0082_jpg.rf.4a1202d4ba8e1edff5c4434927e174da.txt CT-2_DJI_0082_jpg.rf.4a1202d4ba8e1edff5c4434927e174da.jpg [9.0, 32.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/VI1_HI4_CO3_FC0_OS3_TF0_0_20210203_LP_128_jpg.rf.8aa4f4fa42b9cffac5e1bab78e436a41.txt VI1_HI4_CO3_FC0_OS3_TF0_0_20210203_LP_128_jpg.rf.8aa4f4fa42b9cffac5e1bab78e436a41.jpg [6.0, 6.0, 6.0, 6.0, 6.0, 25.0, 25.0, 25.0, 26.0, 26.0, 26.0]\n",
      "/kaggle/input/power-line-assets-version-2/Power Line Assets Labels/Fotos-19-10-2020_DJI_0067_cadeia_isolador_vidro_12_0_jpg.rf.6a7f77c2141564a4ace8a22c2800b5bd.txt Fotos-19-10-2020_DJI_0067_cadeia_isolador_vidro_12_0_jpg.rf.6a7f77c2141564a4ace8a22c2800b5bd.jpg [29.0, 29.0]\n"
     ]
    }
   ],
   "source": [
    "image_dir = \"/kaggle/input/power-line-assets-version-2/Power Line Assets Images\"\n",
    "labels_dir = \"/kaggle/input/power-line-assets-version-2/Power Line Assets Labels\"\n",
    "output_dir_img = \"/kaggle/working/power_assets/images\"\n",
    "output_dir_txt = \"/kaggle/working/power_assets/labels\"\n",
    "img_names = os.listdir(image_dir)\n",
    "process_images_in_batches2(img_names, image_dir, labels_dir, output_dir_img, output_dir_txt, transform1, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T21:25:35.660191Z",
     "iopub.status.busy": "2024-07-28T21:25:35.659106Z",
     "iopub.status.idle": "2024-07-28T21:25:35.671841Z",
     "shell.execute_reply": "2024-07-28T21:25:35.668775Z",
     "shell.execute_reply.started": "2024-07-28T21:25:35.660140Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648\n",
      "648\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir(\"/kaggle/working/power_assets_v2/images/test\")))\n",
    "print(len(os.listdir(\"/kaggle/working/power_assets_v2/labels/test\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T20:55:34.310467Z",
     "iopub.status.busy": "2024-07-28T20:55:34.309792Z",
     "iopub.status.idle": "2024-07-28T21:09:10.127661Z",
     "shell.execute_reply": "2024-07-28T21:09:10.126110Z",
     "shell.execute_reply.started": "2024-07-28T20:55:34.310423Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Copy the directories to the dataset directory\n",
    "dataset_directory = '/kaggle/working/power_assets_v2'\n",
    "os.makedirs(dataset_directory, exist_ok=True)\n",
    "images_folder = '/kaggle/input/power-line-assets-editedv2-trainaug/images'\n",
    "labels_folder = '/kaggle/input/power-line-assets-editedv2-trainaug/labels'\n",
    "def copytree(src, dst, symlinks=False, ignore=None):\n",
    "    if not os.path.exists(dst):\n",
    "        os.makedirs(dst)\n",
    "    for item in os.listdir(src):\n",
    "        s = os.path.join(src, item)\n",
    "        d = os.path.join(dst, item)\n",
    "        if os.path.isdir(s):\n",
    "            copytree(s, d, symlinks, ignore)\n",
    "        else:\n",
    "            shutil.copy2(s, d)\n",
    "\n",
    "copytree(images_folder, os.path.join(dataset_directory, 'images'))\n",
    "copytree(labels_folder, os.path.join(dataset_directory, 'labels'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T15:24:56.597394Z",
     "iopub.status.busy": "2024-07-22T15:24:56.596573Z",
     "iopub.status.idle": "2024-07-22T15:24:56.682916Z",
     "shell.execute_reply": "2024-07-22T15:24:56.681780Z",
     "shell.execute_reply.started": "2024-07-22T15:24:56.597357Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17260 17260 31804 31804\n"
     ]
    }
   ],
   "source": [
    "l1 = os.listdir(\"/kaggle/working/power_assets/images/train\")\n",
    "l2 = os.listdir(\"/kaggle/working/power_assets/labels/train\")\n",
    "l3 = os.listdir(\"/kaggle/working/Augmented_images\")\n",
    "l4 = os.listdir(\"/kaggle/working/Augmented_texts\")\n",
    "print(len(l1), len(l2), len(l3), len(l4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T21:14:34.730217Z",
     "iopub.status.busy": "2024-07-28T21:14:34.728522Z",
     "iopub.status.idle": "2024-07-28T21:14:39.844124Z",
     "shell.execute_reply": "2024-07-28T21:14:39.842738Z",
     "shell.execute_reply.started": "2024-07-28T21:14:34.730150Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aug_0-aug-000000986h_jpeg.rf.926232e83d6364f82adea1bc9a52c832.jpg', 'aug_0-aug-000006140h_JPG.rf.fa4d6325f6eb9b738aa203460de960d5.jpg'] ['aug_0-aug-000000986h_jpeg.rf.926232e83d6364f82adea1bc9a52c832.txt', 'aug_0-aug-000006140h_JPG.rf.fa4d6325f6eb9b738aa203460de960d5.txt']\n"
     ]
    }
   ],
   "source": [
    "images = os.listdir(\"/kaggle/working/Augmented_images_val\")\n",
    "labels = os.listdir(\"/kaggle/working/Augmented_texts_val\")\n",
    "images.sort()\n",
    "labels.sort()\n",
    "print(images[:2], labels[:2])\n",
    "def sort_and_copy_files(source_dir, target_dir, sorted_files):\n",
    "\n",
    "    for file_name in sorted_files:\n",
    "        source_file_path = os.path.join(source_dir, file_name)\n",
    "        target_file_path = os.path.join(target_dir, file_name)\n",
    "    \n",
    "        if not os.path.exists(target_file_path):\n",
    "            shutil.copy2(source_file_path, target_file_path)\n",
    "        else:\n",
    "            print(f\"File {file_name} already exists in {target_dir}, skipping copy.\")\n",
    "\n",
    "\n",
    "sort_and_copy_files(\"/kaggle/working/Augmented_images_val\", \"/kaggle/working/power_assets_v2/images/valid\", images)\n",
    "sort_and_copy_files(\"/kaggle/working/Augmented_texts_val\", \"/kaggle/working/power_assets_v2/labels/valid\", labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T15:25:37.122535Z",
     "iopub.status.busy": "2024-07-22T15:25:37.121748Z",
     "iopub.status.idle": "2024-07-22T15:25:37.222896Z",
     "shell.execute_reply": "2024-07-22T15:25:37.221779Z",
     "shell.execute_reply.started": "2024-07-22T15:25:37.122485Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49064 49064\n"
     ]
    }
   ],
   "source": [
    "train_label = os.listdir(\"/kaggle/working/power_assets/labels/train\")\n",
    "train_img = os.listdir(\"/kaggle/working/power_assets/images/train\")\n",
    "print(len(train_label), len(train_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T19:00:01.880241Z",
     "iopub.status.busy": "2024-07-28T19:00:01.879693Z",
     "iopub.status.idle": "2024-07-28T19:00:04.393752Z",
     "shell.execute_reply": "2024-07-28T19:00:04.392243Z",
     "shell.execute_reply.started": "2024-07-28T19:00:01.880187Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split into train, valid, and test sets:\n",
      "Train images and labels: 15103\n",
      "Validation images and labels: 4315\n",
      "Test images and labels: 2158\n"
     ]
    }
   ],
   "source": [
    "# creating train test valid\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "def split_data(image_dir, label_dir, train_ratio=0.7, valid_ratio=0.2, test_ratio=0.1):\n",
    "    os.makedirs(os.path.join(image_dir, \"train\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(image_dir, \"valid\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(image_dir, \"test\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(label_dir, \"train\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(label_dir, \"valid\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(label_dir, \"test\"), exist_ok=True)\n",
    "\n",
    "    # Get list of all images\n",
    "    images = [f for f in os.listdir(image_dir) if f.endswith('.jpg') or f.endswith('.png')]\n",
    "    \n",
    "    # Shuffle images to ensure random split\n",
    "    random.seed(40)\n",
    "    random.shuffle(images)\n",
    "\n",
    "    # Compute split indices\n",
    "    total_images = len(images)\n",
    "    train_end = int(train_ratio * total_images)\n",
    "    valid_end = int((train_ratio + valid_ratio) * total_images)\n",
    "\n",
    "    # Split images into train, valid, and test sets\n",
    "    train_images = images[:train_end]\n",
    "    valid_images = images[train_end:valid_end]\n",
    "    test_images = images[valid_end:]\n",
    "\n",
    "    # Function to move files from one folder to another\n",
    "    def move_files(file_list, src_image_dir, src_label_dir, dst_image_dir, dst_label_dir):\n",
    "        for img in file_list:\n",
    "            # Corresponding label file\n",
    "            label_file = os.path.splitext(img)[0] + '.txt'\n",
    "            if os.path.exists(os.path.join(src_label_dir, label_file)):\n",
    "                # Move image\n",
    "                shutil.move(os.path.join(src_image_dir, img), os.path.join(dst_image_dir, img))\n",
    "                # Move label\n",
    "                shutil.move(os.path.join(src_label_dir, label_file), os.path.join(dst_label_dir, label_file))\n",
    "            else:\n",
    "                print(f\"Warning: Label file {label_file} does not exist, skipping {img}\")\n",
    "\n",
    "    # Move images and labels to respective folders\n",
    "    move_files(train_images, image_dir, label_dir, os.path.join(image_dir, 'train'), os.path.join(label_dir, 'train'))\n",
    "    move_files(valid_images, image_dir, label_dir, os.path.join(image_dir, 'valid'), os.path.join(label_dir, 'valid'))\n",
    "    move_files(test_images, image_dir, label_dir, os.path.join(image_dir, 'test'), os.path.join(label_dir, 'test'))\n",
    "\n",
    "    print(f\"Data split into train, valid, and test sets:\")\n",
    "    print(f\"Train images and labels: {len(train_images)}\")\n",
    "    print(f\"Validation images and labels: {len(valid_images)}\")\n",
    "    print(f\"Test images and labels: {len(test_images)}\")\n",
    "\n",
    "# Example usage\n",
    "image_dir = \"/kaggle/working/power_assets/images/\"\n",
    "label_dir = \"/kaggle/working/power_assets/labels/\"\n",
    "\n",
    "split_data(image_dir, label_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-05T06:28:26.291626Z",
     "iopub.status.idle": "2024-07-05T06:28:26.292006Z",
     "shell.execute_reply": "2024-07-05T06:28:26.291814Z",
     "shell.execute_reply.started": "2024-07-05T06:28:26.291798Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# validing the dataset\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "\n",
    "def load_labels(label_path):\n",
    "    labels = []\n",
    "    with open(label_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            labels.append(line.strip().split())\n",
    "    return labels\n",
    "\n",
    "def plot_image_with_labels(image_path, label_path, class_dict):\n",
    "    \n",
    "    image = Image.open(image_path)\n",
    "    image_width, image_height = image.size\n",
    "\n",
    "    labels = load_labels(label_path)\n",
    "\n",
    "    fig, ax = plt.subplots(1)\n",
    "    ax.imshow(image)\n",
    "\n",
    "\n",
    "    for label in labels:\n",
    "        class_id = int(label[0])\n",
    "        x_center = float(label[1]) * image_width\n",
    "        y_center = float(label[2]) * image_height\n",
    "        width = float(label[3]) * image_width\n",
    "        height = float(label[4]) * image_height\n",
    "\n",
    "        rect = patches.Rectangle(\n",
    "            (x_center - width / 2, y_center - height / 2),\n",
    "            width, height,\n",
    "            linewidth=2, edgecolor='r', facecolor='none'\n",
    "        )\n",
    "\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        ax.text(x_center - width / 2, y_center - height / 2 - 10, \n",
    "                class_dict.get(class_id, 'Unknown'), \n",
    "                color='white', backgroundcolor='red', fontsize=12, \n",
    "                weight='bold')\n",
    "\n",
    "    plt.axis('off')  \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "image_path = \"/kaggle/working/power_assets/images/train/\"\n",
    "label_path = \"/kaggle/working/power_assets/labels/train/\"\n",
    "images = os.listdir(image_path)\n",
    "labels = os.listdir(label_path)\n",
    "\n",
    "class_dict = yolo_categories \n",
    "\n",
    "plot_image_with_labels(image_path+images[75], label_path+labels[75], class_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T21:26:54.772974Z",
     "iopub.status.busy": "2024-07-28T21:26:54.771358Z",
     "iopub.status.idle": "2024-07-28T21:31:33.655385Z",
     "shell.execute_reply": "2024-07-28T21:31:33.653423Z",
     "shell.execute_reply.started": "2024-07-28T21:26:54.772887Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting upload for file images.zip\n",
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.6.17 / client 1.6.14)\n",
      "100%|██████████████████████████████████████| 3.15G/3.15G [00:33<00:00, 99.8MB/s]\n",
      "Upload successful: images.zip (3GB)\n",
      "Starting upload for file labels.zip\n",
      "100%|██████████████████████████████████████| 20.0M/20.0M [00:00<00:00, 22.7MB/s]\n",
      "Upload successful: labels.zip (20MB)\n",
      "Your private Dataset is being created. Please check progress at https://www.kaggle.com/datasets/sepehrsimkhah/power-line-assets-editedv2-trainvalaug\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "# Upload kaggle.json and move it to the .kaggle directory\n",
    "kaggle_json = '/kaggle/input/kaggle-is-amazing/kaggle.json'\n",
    "kaggle_dir = '/root/.kaggle'\n",
    "os.makedirs(kaggle_dir, exist_ok=True)\n",
    "shutil.copy(kaggle_json, os.path.join(kaggle_dir, 'kaggle.json'))\n",
    "os.chmod(os.path.join(kaggle_dir, 'kaggle.json'), 0o600)\n",
    "\n",
    "# Load the Kaggle credentials from the kaggle.json file\n",
    "with open(os.path.join(kaggle_dir, 'kaggle.json')) as f:\n",
    "    kaggle_credentials = json.load(f)\n",
    "    kaggle_username = kaggle_credentials['username']\n",
    "\n",
    "# Define the dataset details\n",
    "dataset_name = 'power-line-assets-editedv2-trainvalaug'\n",
    "dataset_title = 'Power-Line-Assets-editedv2-trainvalaug'\n",
    "dataset_directory = '/kaggle/working/power_assets_v2'\n",
    "# images_folder = '/kaggle/working/power_assets/images/'\n",
    "# labels_folder = '/kaggle/working/power_assets/labels/'\n",
    "# Ensure the dataset directory exists\n",
    "# os.makedirs(dataset_directory, exist_ok=True)\n",
    "\n",
    "# Move your prepared data to the dataset directory\n",
    "# For example, if you have already saved your images and labels in respective folders:\n",
    "\n",
    "\n",
    "# Copy the directories to the dataset directory\n",
    "# def copytree(src, dst, symlinks=False, ignore=None):\n",
    "#     if not os.path.exists(dst):\n",
    "#         os.makedirs(dst)\n",
    "#     for item in os.listdir(src):\n",
    "#         s = os.path.join(src, item)\n",
    "#         d = os.path.join(dst, item)\n",
    "#         if os.path.isdir(s):\n",
    "#             copytree(s, d, symlinks, ignore)\n",
    "#         else:\n",
    "#             shutil.copy2(s, d)\n",
    "\n",
    "# copytree(images_folder, os.path.join(dataset_directory, 'images'))\n",
    "# copytree(labels_folder, os.path.join(dataset_directory, 'labels'))\n",
    "\n",
    "# Create a dataset-metadata.json file\n",
    "metadata = {\n",
    "    'title': dataset_title,\n",
    "    'id': f'{kaggle_username}/{dataset_name}',\n",
    "    'licenses': [\n",
    "        {\n",
    "            'name': 'CC0-1.0',\n",
    "            'url': 'http://creativecommons.org/publicdomain/zero/1.0/'\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "metadata_file = os.path.join(dataset_directory, 'dataset-metadata.json')\n",
    "with open(metadata_file, 'w') as f:\n",
    "    json.dump(metadata, f)\n",
    "\n",
    "# Use the Kaggle API to upload the dataset\n",
    "!kaggle datasets create -p {dataset_directory} --dir-mode zip\n",
    "\n",
    "# Optionally, you can add additional flags such as --public to make it public\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T16:08:07.249993Z",
     "iopub.status.busy": "2024-07-22T16:08:07.249758Z",
     "iopub.status.idle": "2024-07-22T16:26:18.566728Z",
     "shell.execute_reply": "2024-07-22T16:26:18.565933Z",
     "shell.execute_reply.started": "2024-07-22T16:08:07.249970Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define paths to current and target directories\n",
    "base_dir = \"/kaggle/input/power-line-assets-editedv2\"\n",
    "target_dir = \"/kaggle/working/power-line-assets-editedv2\"\n",
    "current_images_dir = os.path.join(base_dir, \"Power Line Assets Images\")\n",
    "current_labels_dir = os.path.join(base_dir, \"Power Line Assets Labels\")\n",
    "target_images_dir = os.path.join(target_dir, \"images\")\n",
    "target_labels_dir = os.path.join(target_dir, \"labels\")\n",
    "\n",
    "# Function to copy files from source to destination directory\n",
    "def copy_files(source_dir, target_dir):\n",
    "    # Iterate through train, valid, test directories\n",
    "    for split in ['train', 'valid', 'test']:\n",
    "        source_split_dir = os.path.join(source_dir, split)\n",
    "        target_split_dir = os.path.join(target_dir, split)\n",
    "        os.makedirs(target_split_dir, exist_ok=True)\n",
    "\n",
    "        # Iterate through files in source split directory\n",
    "        for filename in os.listdir(source_split_dir):\n",
    "            source_file_path = os.path.join(source_split_dir, filename)\n",
    "            target_file_path = os.path.join(target_split_dir, filename)\n",
    "            \n",
    "            # Copy file from source to target directory\n",
    "            shutil.copy(source_file_path, target_file_path)\n",
    "\n",
    "# Copy images\n",
    "copy_files(current_images_dir, target_images_dir)\n",
    "\n",
    "# Copy labels\n",
    "copy_files(current_labels_dir, target_labels_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T16:42:26.585782Z",
     "iopub.status.busy": "2024-07-22T16:42:26.585323Z",
     "iopub.status.idle": "2024-07-22T16:42:26.608451Z",
     "shell.execute_reply": "2024-07-22T16:42:26.607675Z",
     "shell.execute_reply.started": "2024-07-22T16:42:26.585752Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# creating yaml file\n",
    "path = \"/kaggle/working/power-line-assets-editedv2/\"\n",
    "cust_yaml = {\n",
    "    \"path\":path,\n",
    "    \"train\": \"images/train\",\n",
    "    \"val\": \"images/valid\",\n",
    "    \"test\": \"images/test\",\n",
    "    \"nc\": 38,\n",
    "    \"names\": [\"Yoke\",\"Yoke Suspension\",\"Spacer\", \"Damper - Stockbridge\", \"Lightning Rod Shackle\",\n",
    "              \"Lightning Rod Suspension\", \"Polymer Insulator\", \"Glass Insulator\", \"Tower ID Plate\",\n",
    "              \"Vari-grip\", \"Polymer Insulator Lower Shackle\",\"Polymer Insulator Upper Shackle\",\n",
    "              \"Polymer Insulator Tower Shackle\",\"Glass Insulator Big Shankle\",\"Glass Insulator Small Shankle\",\n",
    "              \"Glass Insulator Tower Shankle\",\"Damper - Spiral\",\"Sphere\",\"Cable\",\"Fuse Cutout - Closed\",\n",
    "              \"Broken Cable\",\"Tower\",\"Broken Polymer-insulator\",\"Vegetation\",\"Transformer\",\"Connector\",\n",
    "              \"Overhead Switch\",\"Broken Vari-Grip\",\"Broken Polymer Insulator Upper Shackle\",\"Broken Glass Insulator\",\n",
    "              \"Broken Lightning Rod suspension\",\"Broken Yoke Suspension\",\"Bird Nest\",\"ALS\",\"Damaged ALS\",\n",
    "              \"Fuse Cutout - Open\",\"Surge Arrester\", \"Broken-Damper-Stockbridge\"\n",
    "             ]\n",
    "}\n",
    "with open('/kaggle/working/power.yaml', 'w') as file:\n",
    "    yaml.dump(cust_yaml, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T05:56:55.603799Z",
     "iopub.status.busy": "2024-07-19T05:56:55.603466Z",
     "iopub.status.idle": "2024-07-19T05:56:55.619407Z",
     "shell.execute_reply": "2024-07-19T05:56:55.618346Z",
     "shell.execute_reply.started": "2024-07-19T05:56:55.603771Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images path exists: True\n",
      "Valid images path exists: True\n",
      "Test images path exists: True\n",
      "Train labels path exists: True\n",
      "Valid labels path exists: True\n",
      "Test labels path exists: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data_dir = \"/kaggle/working/power-line-assets-editedv2\"\n",
    "print(\"Train images path exists:\", os.path.exists(os.path.join(data_dir, \"images/train\")))\n",
    "print(\"Valid images path exists:\", os.path.exists(os.path.join(data_dir, \"images/valid\")))\n",
    "print(\"Test images path exists:\", os.path.exists(os.path.join(data_dir, \"images/test\")))\n",
    "print(\"Train labels path exists:\", os.path.exists(os.path.join(data_dir, \"labels/train\")))\n",
    "print(\"Valid labels path exists:\", os.path.exists(os.path.join(data_dir, \"labels/valid\")))\n",
    "print(\"Test labels path exists:\", os.path.exists(os.path.join(data_dir, \"labels/test\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T19:49:30.760981Z",
     "iopub.status.busy": "2024-07-06T19:49:30.760716Z",
     "iopub.status.idle": "2024-07-06T19:49:30.814947Z",
     "shell.execute_reply": "2024-07-06T19:49:30.814230Z",
     "shell.execute_reply.started": "2024-07-06T19:49:30.760958Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "def clear_cuda_cache():\n",
    "    torch.cuda.empty_cache()\n",
    "    subprocess.run(['nvidia-smi', '--gpu-reset'], capture_output=True, text=True)\n",
    "    \n",
    "# Clear the CUDA cache\n",
    "clear_cuda_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T06:00:26.604839Z",
     "iopub.status.busy": "2024-07-19T06:00:26.603958Z",
     "iopub.status.idle": "2024-07-19T15:56:48.766620Z",
     "shell.execute_reply": "2024-07-19T15:56:48.764345Z",
     "shell.execute_reply.started": "2024-07-19T06:00:26.604803Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transferred 475/475 items from pretrained weights\n",
      "Ultralytics YOLOv8.2.60 🚀 Python-3.10.13 torch-2.1.2 CUDA:1 (Tesla T4, 15095MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.yaml, data=/kaggle/working/power.yaml, epochs=40, time=None, patience=100, batch=-1, imgsz=640, save=True, save_period=2, cache=False, device=1, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=0.6, mixup=0.4, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train2\n",
      "Overriding model.yaml nc=80 with nc=38\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3797698  ultralytics.nn.modules.head.Detect           [38, [192, 384, 576]]         \n",
      "YOLOv8m summary: 295 layers, 25,878,322 parameters, 25,878,306 gradients, 79.2 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train2', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20240719_060054-8csm2tok</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ssimkhah-simkah%20group/YOLOv8/runs/8csm2tok' target=\"_blank\">train2</a></strong> to <a href='https://wandb.ai/ssimkhah-simkah%20group/YOLOv8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ssimkhah-simkah%20group/YOLOv8' target=\"_blank\">https://wandb.ai/ssimkhah-simkah%20group/YOLOv8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ssimkhah-simkah%20group/YOLOv8/runs/8csm2tok' target=\"_blank\">https://wandb.ai/ssimkhah-simkah%20group/YOLOv8/runs/8csm2tok</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6.25M/6.25M [00:00<00:00, 75.9MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=640 at 60.0% CUDA memory utilization.\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (Tesla T4) 14.74G total, 0.30G reserved, 0.23G allocated, 14.21G free\n",
      "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
      "    25878322       79.18         0.652         44.73         131.3        (1, 3, 640, 640)                    list\n",
      "    25878322       158.4         1.007         32.31         72.52        (2, 3, 640, 640)                    list\n",
      "    25878322       316.7         1.806         39.69         74.44        (4, 3, 640, 640)                    list\n",
      "    25878322       633.5         3.261         73.04           106        (8, 3, 640, 640)                    list\n",
      "    25878322        1267         6.306         145.4         177.4       (16, 3, 640, 640)                    list\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 21 for CUDA:0 8.71G/14.74G (59%) ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/power-line-assets-editedv2/labels/train... 55020 images, 0 backgrounds, 0 corrupt: 100%|██████████| 55020/55020 [00:50<00:00, 1099.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/power-line-assets-editedv2/labels/train.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/power-line-assets-editedv2/labels/valid... 4891 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4891/4891 [00:04<00:00, 1105.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/power-line-assets-editedv2/labels/valid.cache\n",
      "Plotting labels to runs/detect/train2/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0004921875), 83 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train2\u001b[0m\n",
      "Starting training for 40 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/40      9.87G      2.513       4.13      2.436        104        640: 100%|██████████| 2620/2620 [28:38<00:00,  1.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 117/117 [01:09<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4891      17412      0.716      0.106      0.132     0.0805\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/40        10G      2.168      3.555      2.258        224        640: 100%|██████████| 2620/2620 [28:15<00:00,  1.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 117/117 [01:07<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4891      17412      0.564    0.00943     0.0187    0.00846\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/40      9.64G      2.175      3.666      2.303        135        640: 100%|██████████| 2620/2620 [28:04<00:00,  1.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 117/117 [01:09<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4891      17412      0.711     0.0907       0.11     0.0664\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/40      10.5G      2.163      3.696      2.318        191        640: 100%|██████████| 2620/2620 [28:02<00:00,  1.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 117/117 [01:09<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4891      17412      0.686      0.125      0.149     0.0928\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/40      10.5G      2.063      3.491      2.239        142        640: 100%|██████████| 2620/2620 [28:03<00:00,  1.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 117/117 [01:10<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4891      17412      0.832      0.141      0.176       0.11\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/40      10.6G       1.98      3.302      2.164        104        640: 100%|██████████| 2620/2620 [28:04<00:00,  1.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 117/117 [01:10<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4891      17412      0.687      0.191      0.206       0.13\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/40       9.9G      1.926      3.175      2.119        206        640: 100%|██████████| 2620/2620 [28:05<00:00,  1.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 117/117 [01:10<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4891      17412      0.733      0.199      0.226      0.143\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/40        10G      1.893      3.085      2.079        149        640: 100%|██████████| 2620/2620 [28:03<00:00,  1.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 117/117 [01:10<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4891      17412      0.664      0.221      0.243      0.153\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/40      9.58G      1.863      3.024      2.058        180        640: 100%|██████████| 2620/2620 [28:04<00:00,  1.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 117/117 [01:10<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4891      17412      0.761       0.22      0.252      0.163\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/40      10.3G      1.843      2.979      2.041        131        640: 100%|██████████| 2620/2620 [28:01<00:00,  1.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 117/117 [01:10<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4891      17412      0.693      0.231       0.26      0.168\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/40        10G      1.819       2.93      2.019        151        640: 100%|██████████| 2620/2620 [28:01<00:00,  1.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 117/117 [01:10<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4891      17412      0.756      0.231      0.267      0.173\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/40      9.72G      1.801      2.882      2.002        102        640: 100%|██████████| 2620/2620 [28:02<00:00,  1.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 117/117 [01:10<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4891      17412      0.755       0.24      0.278      0.181\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/40      9.69G      1.789      2.845      1.986         93        640: 100%|██████████| 2620/2620 [28:04<00:00,  1.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 117/117 [01:10<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4891      17412      0.656      0.257      0.283      0.186\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/40      9.65G      1.761      2.789      1.964        100        640: 100%|██████████| 2620/2620 [28:04<00:00,  1.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 117/117 [01:10<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4891      17412      0.693      0.263      0.292      0.191\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/40      10.8G      1.748      2.765      1.953        103        640: 100%|██████████| 2620/2620 [28:06<00:00,  1.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 117/117 [01:10<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4891      17412      0.677      0.268      0.294      0.195\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/40      10.1G      1.736      2.733      1.941        194        640: 100%|██████████| 2620/2620 [28:07<00:00,  1.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 117/117 [01:10<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4891      17412      0.674      0.273        0.3      0.197\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/40        10G      1.728      2.703      1.928         89        640: 100%|██████████| 2620/2620 [28:09<00:00,  1.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 117/117 [01:10<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4891      17412      0.659      0.281      0.306      0.201\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/40      10.1G      1.716      2.692      1.921        134        640: 100%|██████████| 2620/2620 [28:09<00:00,  1.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 117/117 [01:10<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4891      17412       0.68      0.282      0.313      0.206\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/40      10.1G      1.706      2.649      1.908        204        640: 100%|██████████| 2620/2620 [28:08<00:00,  1.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 117/117 [01:10<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4891      17412      0.698      0.287      0.316      0.209\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/40      9.99G      1.697      2.644      1.903        125        640: 100%|██████████| 2620/2620 [28:08<00:00,  1.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 117/117 [01:10<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4891      17412      0.699      0.288      0.318       0.21\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/40      9.72G      1.691       2.63      1.899        128        640:  27%|██▋       | 701/2620 [07:31<20:37,  1.55it/s]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolov8m.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolov8m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# resume = True if there are checkpoints\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/kaggle/working/power.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_period\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmixup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmosaic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.6\u001b[39;49m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/engine/model.py:652\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m    651\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[0;32m--> 652\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py:204\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 204\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py:381\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mamp):\n\u001b[1;32m    380\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_batch(batch)\n\u001b[0;32m--> 381\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_items \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    383\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m world_size\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/nn/tasks.py:101\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124;03mForward pass of the model on a single scale. Wrapper for `_forward_once` method.\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m    (torch.Tensor): The output of the network.\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/nn/tasks.py:283\u001b[0m, in \u001b[0;36mBaseModel.loss\u001b[0;34m(self, batch, preds)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_criterion()\n\u001b[1;32m    282\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m preds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m preds\n\u001b[0;32m--> 283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/utils/loss.py:240\u001b[0m, in \u001b[0;36mv8DetectionLoss.__call__\u001b[0;34m(self, preds, batch)\u001b[0m\n\u001b[1;32m    229\u001b[0m pred_bboxes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbbox_decode(anchor_points, pred_distri)  \u001b[38;5;66;03m# xyxy, (b, h*w, 4)\u001b[39;00m\n\u001b[1;32m    231\u001b[0m _, target_bboxes, target_scores, fg_mask, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massigner(\n\u001b[1;32m    232\u001b[0m     pred_scores\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39msigmoid(),\n\u001b[1;32m    233\u001b[0m     (pred_bboxes\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m*\u001b[39m stride_tensor)\u001b[38;5;241m.\u001b[39mtype(gt_bboxes\u001b[38;5;241m.\u001b[39mdtype),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    237\u001b[0m     mask_gt,\n\u001b[1;32m    238\u001b[0m )\n\u001b[0;32m--> 240\u001b[0m target_scores_sum \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtarget_scores\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;66;03m# Cls loss\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;66;03m# loss[1] = self.varifocal_loss(pred_scores, target_scores, target_labels) / target_scores_sum  # VFL way\u001b[39;00m\n\u001b[1;32m    244\u001b[0m loss[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbce(pred_scores, target_scores\u001b[38;5;241m.\u001b[39mto(dtype))\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m/\u001b[39m target_scores_sum  \u001b[38;5;66;03m# BCE\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "# os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:64'\n",
    "# training\n",
    "model = YOLO(\"yolov8m.yaml\")\n",
    "model = YOLO(\"yolov8m.pt\")\n",
    "model = YOLO(\"yolov8m.yaml\").load(\"yolov8m.pt\")\n",
    "# resume = True if there are checkpoints\n",
    "result = model.train(data=\"/kaggle/working/power.yaml\", \n",
    "    epochs=40,\n",
    "    imgsz=640,\n",
    "    batch=-1,\n",
    "    save_period=2,\n",
    "    device=1,\n",
    "    mixup=0.4, \n",
    "    mosaic=0.6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-18T05:15:17.724958Z",
     "iopub.status.idle": "2024-07-18T05:15:17.725405Z",
     "shell.execute_reply": "2024-07-18T05:15:17.725207Z",
     "shell.execute_reply.started": "2024-07-18T05:15:17.725180Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "model_save_path = \"/kaggle/working/model/power_assets_detection_with_defect_yolov8.pt\"\n",
    "torch.save(model.model.state_dict(), model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation model\n",
    "metrics = model.val(data=\"/kaggle/working/power.yaml\", imgsz=640, batch=16, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# testing\n",
    "test_list = os.listdir(\"/kaggle/input/power_line_assetsv2/images/test\")\n",
    "model.predict(\"/kaggle/input/power_line_assetsv2/\"+test_list[3], save=True, imgsz=640, conf=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Loading \n",
    "model_save_path = \"/kaggle/working/model/power_assets_detection_with_defect\n",
    "\n",
    "model = YOLO(\"yolov8m.yaml\")\n",
    "\n",
    "model.model.load_state_dict(torch.load(model_save_path))\n",
    "model.model.eval()  # Set the model to evaluation mode if you are going to use it for inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Training with yolo version 9 medium***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov9m.yaml\")\n",
    "model = YOLO(\"yolov9m.pt\")\n",
    "model = YOLO(\"yolov9m.yaml\").load(\"yolov9m.pt\")\n",
    "# resume = True if there are checkpoints\n",
    "result = model.train(data=\"/kaggle/working/power.yaml\", \n",
    "    epochs=40,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    save_period=2,\n",
    "    device=0,\n",
    "    mixup=0.4, \n",
    "    mosaic=0.6, \n",
    "    dropout=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "model_save_path = \"/kaggle/working/model/power_assets_detection_with_defect_yolov9.pt\"\n",
    "torch.save(model.model.state_dict(), model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation model\n",
    "metrics = model.val(data=\"/kaggle/working/power.yaml\", imgsz=640, batch=16, device=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "model.predict(\"bus.jpg\", save=True, imgsz=640, conf=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Loading \n",
    "model_save_path = \"/kaggle/working/model/power_assets_detection_with_defect_yolov9\n",
    "\n",
    "model = YOLO(\"yolov9m.yaml\")\n",
    "\n",
    "model.model.load_state_dict(torch.load(model_save_path))\n",
    "model.model.eval()  # Set the model to evaluation mode if you are going to use it for inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Training with yolo version 10 medium***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov10s.yaml\")\n",
    "model = YOLO(\"yolov10s.pt\")\n",
    "model = YOLO(\"yolov10s.yaml\").load(\"yolov10s.pt\")\n",
    "# resume = True if there are checkpoints\n",
    "result = model.train(data=\"/kaggle/working/power.yaml\", \n",
    "    epochs=20,\n",
    "    imgsz=640,\n",
    "    batch=-1,\n",
    "    save_period=2,\n",
    "    device=1,\n",
    "    mixup=0.4, \n",
    "    mosaic=0.6, \n",
    "    dropout=0.2,\n",
    "    optimizer=\"AdamW\",\n",
    "    workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "model_save_path = \"/kaggle/working/model/power_assets_detection_with_defect_yolov10.pt\"\n",
    "torch.save(model.model.state_dict(), model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation model\n",
    "metrics = model.val(data=\"/kaggle/working/power.yaml\", imgsz=640, batch=16, device=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "model.predict(\"bus.jpg\", save=True, imgsz=640, conf=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Loading \n",
    "model_save_path = \"/kaggle/working/model/power_assets_detection_with_defect_yolov10\n",
    "\n",
    "model = YOLO(\"yolov10m.yaml\")\n",
    "\n",
    "model.model.load_state_dict(torch.load(model_save_path))\n",
    "model.model.eval()  # Set the model to evaluation mode if you are going to use it for inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T16:42:26.609689Z",
     "iopub.status.busy": "2024-07-22T16:42:26.609439Z",
     "iopub.status.idle": "2024-07-22T16:52:40.296184Z",
     "shell.execute_reply": "2024-07-22T16:52:40.294674Z",
     "shell.execute_reply.started": "2024-07-22T16:42:26.609664Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.62 🚀 Python-3.10.14 torch-2.3.0+cu121 CPU (Intel Xeon 2.00GHz)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/kaggle/input/meowmeow/last(2)-yolo9.pt, data=/kaggle/working/power.yaml, epochs=100, time=None, patience=100, batch=128, imgsz=640, save=True, save_period=2, cache=False, device=None, workers=8, project=None, name=Power Assets with Yolov94, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.2, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=0.6, mixup=0.4, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/Power Assets with Yolov94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before InitGoogle() is written to STDERR\n",
      "E0000 00:00:1721666551.262794     699 common_lib.cc:798] Could not set metric server port: INVALID_ARGUMENT: Could not find SliceBuilder port 8471 in any of the 0 ports provided in `tpu_process_addresses`=\"local\"\n",
      "=== Source Location Trace: === \n",
      "learning/45eac/tfrc/runtime/common_lib.cc:479\n",
      "D0722 16:42:31.319674310     699 config.cc:196]                        gRPC EXPERIMENT call_status_override_on_cancellation   OFF (default:OFF)\n",
      "D0722 16:42:31.319695429     699 config.cc:196]                        gRPC EXPERIMENT call_v3                                OFF (default:OFF)\n",
      "D0722 16:42:31.319698804     699 config.cc:196]                        gRPC EXPERIMENT canary_client_privacy                  ON  (default:ON)\n",
      "D0722 16:42:31.319701207     699 config.cc:196]                        gRPC EXPERIMENT capture_base_context                   ON  (default:ON)\n",
      "D0722 16:42:31.319703595     699 config.cc:196]                        gRPC EXPERIMENT client_idleness                        ON  (default:ON)\n",
      "D0722 16:42:31.319705906     699 config.cc:196]                        gRPC EXPERIMENT client_privacy                         ON  (default:ON)\n",
      "D0722 16:42:31.319708173     699 config.cc:196]                        gRPC EXPERIMENT dapper_request_wire_size               OFF (default:OFF)\n",
      "D0722 16:42:31.319710378     699 config.cc:196]                        gRPC EXPERIMENT empty_experiment                       OFF (default:OFF)\n",
      "D0722 16:42:31.319712534     699 config.cc:196]                        gRPC EXPERIMENT event_engine_client                    OFF (default:OFF)\n",
      "D0722 16:42:31.319714702     699 config.cc:196]                        gRPC EXPERIMENT event_engine_dns                       ON  (default:ON)\n",
      "D0722 16:42:31.319716950     699 config.cc:196]                        gRPC EXPERIMENT event_engine_listener                  ON  (default:ON)\n",
      "D0722 16:42:31.319719148     699 config.cc:196]                        gRPC EXPERIMENT free_large_allocator                   OFF (default:OFF)\n",
      "D0722 16:42:31.319721495     699 config.cc:196]                        gRPC EXPERIMENT google_no_envelope_resolver            OFF (default:OFF)\n",
      "D0722 16:42:31.319723682     699 config.cc:196]                        gRPC EXPERIMENT http2_stats_fix                        OFF (default:OFF)\n",
      "D0722 16:42:31.319725830     699 config.cc:196]                        gRPC EXPERIMENT keepalive_fix                          OFF (default:OFF)\n",
      "D0722 16:42:31.319727989     699 config.cc:196]                        gRPC EXPERIMENT keepalive_server_fix                   ON  (default:ON)\n",
      "D0722 16:42:31.319730283     699 config.cc:196]                        gRPC EXPERIMENT loas_do_not_prefer_rekey_next_protocol OFF (default:OFF)\n",
      "D0722 16:42:31.319732516     699 config.cc:196]                        gRPC EXPERIMENT loas_prod_to_cloud_prefer_pfs_ciphers  OFF (default:OFF)\n",
      "D0722 16:42:31.319734721     699 config.cc:196]                        gRPC EXPERIMENT monitoring_experiment                  ON  (default:ON)\n",
      "D0722 16:42:31.319736950     699 config.cc:196]                        gRPC EXPERIMENT multiping                              OFF (default:OFF)\n",
      "D0722 16:42:31.319739111     699 config.cc:196]                        gRPC EXPERIMENT peer_state_based_framing               OFF (default:OFF)\n",
      "D0722 16:42:31.319741342     699 config.cc:196]                        gRPC EXPERIMENT pending_queue_cap                      ON  (default:ON)\n",
      "D0722 16:42:31.319743565     699 config.cc:196]                        gRPC EXPERIMENT pick_first_happy_eyeballs              ON  (default:ON)\n",
      "D0722 16:42:31.319745789     699 config.cc:196]                        gRPC EXPERIMENT promise_based_client_call              OFF (default:OFF)\n",
      "D0722 16:42:31.319747857     699 config.cc:196]                        gRPC EXPERIMENT promise_based_inproc_transport         OFF (default:OFF)\n",
      "D0722 16:42:31.319749985     699 config.cc:196]                        gRPC EXPERIMENT promise_based_server_call              OFF (default:OFF)\n",
      "D0722 16:42:31.319752224     699 config.cc:196]                        gRPC EXPERIMENT registered_method_lookup_in_transport  ON  (default:ON)\n",
      "D0722 16:42:31.319754478     699 config.cc:196]                        gRPC EXPERIMENT rfc_max_concurrent_streams             ON  (default:ON)\n",
      "D0722 16:42:31.319756774     699 config.cc:196]                        gRPC EXPERIMENT round_robin_delegate_to_pick_first     ON  (default:ON)\n",
      "D0722 16:42:31.319759873     699 config.cc:196]                        gRPC EXPERIMENT rstpit                                 OFF (default:OFF)\n",
      "D0722 16:42:31.319762235     699 config.cc:196]                        gRPC EXPERIMENT schedule_cancellation_over_write       OFF (default:OFF)\n",
      "D0722 16:42:31.319764534     699 config.cc:196]                        gRPC EXPERIMENT server_privacy                         ON  (default:ON)\n",
      "D0722 16:42:31.319766942     699 config.cc:196]                        gRPC EXPERIMENT tcp_frame_size_tuning                  OFF (default:OFF)\n",
      "D0722 16:42:31.319769112     699 config.cc:196]                        gRPC EXPERIMENT tcp_rcv_lowat                          OFF (default:OFF)\n",
      "D0722 16:42:31.319771302     699 config.cc:196]                        gRPC EXPERIMENT trace_record_callops                   OFF (default:OFF)\n",
      "D0722 16:42:31.319773454     699 config.cc:196]                        gRPC EXPERIMENT unconstrained_max_quota_buffer_size    OFF (default:OFF)\n",
      "D0722 16:42:31.319775580     699 config.cc:196]                        gRPC EXPERIMENT v3_backend_metric_filter               OFF (default:OFF)\n",
      "D0722 16:42:31.319777713     699 config.cc:196]                        gRPC EXPERIMENT v3_channel_idle_filters                ON  (default:ON)\n",
      "D0722 16:42:31.319779973     699 config.cc:196]                        gRPC EXPERIMENT v3_compression_filter                  ON  (default:ON)\n",
      "D0722 16:42:31.319782176     699 config.cc:196]                        gRPC EXPERIMENT v3_server_auth_filter                  OFF (default:OFF)\n",
      "D0722 16:42:31.319784310     699 config.cc:196]                        gRPC EXPERIMENT work_serializer_clears_time_cache      OFF (default:OFF)\n",
      "D0722 16:42:31.319786454     699 config.cc:196]                        gRPC EXPERIMENT work_serializer_dispatch               OFF (default:OFF)\n",
      "D0722 16:42:31.319788615     699 config.cc:196]                        gRPC EXPERIMENT write_size_cap                         ON  (default:ON)\n",
      "D0722 16:42:31.319790860     699 config.cc:196]                        gRPC EXPERIMENT write_size_policy                      ON  (default:ON)\n",
      "D0722 16:42:31.319793109     699 config.cc:196]                        gRPC EXPERIMENT wrr_delegate_to_pick_first             ON  (default:ON)\n",
      "I0722 16:42:31.323336048     699 ev_epoll1_linux.cc:123]               grpc epoll fd: 59\n",
      "D0722 16:42:31.323381585     699 ev_posix.cc:113]                      Using polling engine: epoll1\n",
      "D0722 16:42:31.342499995     699 lb_policy_registry.cc:46]             registering LB policy factory for \"priority_experimental\"\n",
      "D0722 16:42:31.342515627     699 lb_policy_registry.cc:46]             registering LB policy factory for \"outlier_detection_experimental\"\n",
      "D0722 16:42:31.343167063     699 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_target_experimental\"\n",
      "D0722 16:42:31.343173006     699 lb_policy_registry.cc:46]             registering LB policy factory for \"pick_first\"\n",
      "D0722 16:42:31.343177206     699 lb_policy_registry.cc:46]             registering LB policy factory for \"round_robin\"\n",
      "D0722 16:42:31.343180883     699 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_round_robin\"\n",
      "D0722 16:42:31.346219005     699 lb_policy_registry.cc:46]             registering LB policy factory for \"grpclb\"\n",
      "D0722 16:42:31.346294230     699 dns_resolver_plugin.cc:43]            Using EventEngine dns resolver\n",
      "D0722 16:42:31.347165635     699 lb_policy_registry.cc:46]             registering LB policy factory for \"rls_experimental\"\n",
      "D0722 16:42:31.348203532     699 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_manager_experimental\"\n",
      "D0722 16:42:31.348846953     699 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_impl_experimental\"\n",
      "D0722 16:42:31.348853005     699 lb_policy_registry.cc:46]             registering LB policy factory for \"cds_experimental\"\n",
      "D0722 16:42:31.348867807     699 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_override_host_experimental\"\n",
      "D0722 16:42:31.348871624     699 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_wrr_locality_experimental\"\n",
      "D0722 16:42:31.348874940     699 lb_policy_registry.cc:46]             registering LB policy factory for \"ring_hash_experimental\"\n",
      "D0722 16:42:31.348878255     699 certificate_provider_registry.cc:33]  registering certificate provider factory for \"file_watcher\"\n",
      "D0722 16:42:31.348918313     699 channel_init.cc:157]                  Filter server-auth not registered, but is referenced in the after clause of grpc-server-authz when building channel stack SERVER_CHANNEL\n",
      "I0722 16:42:31.351599811     699 ev_epoll1_linux.cc:359]               grpc epoll fd: 61\n",
      "I0722 16:42:31.358460545     699 tcp_socket_utils.cc:689]              Disabling AF_INET6 sockets because ::1 is not available.\n",
      "I0722 16:42:31.378543857    1012 socket_utils_common_posix.cc:452]     Disabling AF_INET6 sockets because ::1 is not available.\n",
      "I0722 16:42:31.378593124    1012 socket_utils_common_posix.cc:379]     TCP_USER_TIMEOUT is available. TCP_USER_TIMEOUT will be used thereafter\n",
      "E0722 16:42:31.388983389     699 oauth2_credentials.cc:238]            oauth_fetch: UNKNOWN:C-ares status is not ARES_SUCCESS qtype=A name=metadata.google.internal. is_balancer=0: Domain name not found {created_time:\"2024-07-22T16:42:31.388966949+00:00\", grpc_status:2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     31104  ultralytics.nn.modules.block.ELAN1           [64, 64, 64, 32]              \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.block.AConv           [64, 128]                     \n",
      "  4                  -1  1    258432  ultralytics.nn.modules.block.RepNCSPELAN4    [128, 128, 128, 64, 3]        \n",
      "  5                  -1  1    221568  ultralytics.nn.modules.block.AConv           [128, 192]                    \n",
      "  6                  -1  1    579648  ultralytics.nn.modules.block.RepNCSPELAN4    [192, 192, 192, 96, 3]        \n",
      "  7                  -1  1    442880  ultralytics.nn.modules.block.AConv           [192, 256]                    \n",
      "  8                  -1  1   1028864  ultralytics.nn.modules.block.RepNCSPELAN4    [256, 256, 256, 128, 3]       \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPELAN         [256, 256, 128]               \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    628800  ultralytics.nn.modules.block.RepNCSPELAN4    [448, 192, 192, 96, 3]        \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    283008  ultralytics.nn.modules.block.RepNCSPELAN4    [320, 128, 128, 64, 3]        \n",
      " 16                  -1  1    110784  ultralytics.nn.modules.block.AConv           [128, 96]                     \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    598080  ultralytics.nn.modules.block.RepNCSPELAN4    [288, 192, 192, 96, 3]        \n",
      " 19                  -1  1    221440  ultralytics.nn.modules.block.AConv           [192, 128]                    \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1061632  ultralytics.nn.modules.block.RepNCSPELAN4    [384, 256, 256, 128, 3]       \n",
      " 22        [15, 18, 21]  1   1577794  ultralytics.nn.modules.head.Detect           [38, [128, 192, 256]]         \n",
      "YOLOv9s summary: 917 layers, 7,302,114 parameters, 7,302,098 gradients, 27.5 GFLOPs\n",
      "\n",
      "Transferred 1339/1339 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/Power Assets with Yolov94', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/power-line-assets-editedv2/labels/train.cache... 55020 images, 0 backgrounds, 0 corrupt: 100%|██████████| 55020/55020 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/power-line-assets-editedv2/labels/valid.cache... 4891 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4891/4891 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/Power Assets with Yolov94/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 221 weight(decay=0.0), 228 weight(decay=0.001), 227 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/Power Assets with Yolov94\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100         0G      2.119      3.561      2.264        845        640:   1%|▏         | 6/430 [09:34<11:16:15, 95.70s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/input/meowmeow/last(2)-yolo9.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/kaggle/working/power.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_period\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmixup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmosaic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPower Assets with Yolov9\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/ultralytics/engine/model.py:810\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    807\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m    809\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[0;32m--> 810\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/ultralytics/engine/trainer.py:204\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 204\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/ultralytics/engine/trainer.py:381\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mamp):\n\u001b[1;32m    380\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_batch(batch)\n\u001b[0;32m--> 381\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_items \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    383\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m world_size\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/ultralytics/nn/tasks.py:101\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124;03mForward pass of the model on a single scale. Wrapper for `_forward_once` method.\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m    (torch.Tensor): The output of the network.\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/ultralytics/nn/tasks.py:282\u001b[0m, in \u001b[0;36mBaseModel.loss\u001b[0;34m(self, batch, preds)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcriterion\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_criterion()\n\u001b[0;32m--> 282\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m preds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m preds\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(preds, batch)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/ultralytics/nn/tasks.py:102\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/ultralytics/nn/tasks.py:120\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[0;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/ultralytics/nn/tasks.py:141\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[0;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[0;32m--> 141\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[1;32m    142\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/ultralytics/nn/modules/head.py:57\u001b[0m, in \u001b[0;36mDetect.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_end2end(x)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnl):\n\u001b[0;32m---> 57\u001b[0m     x[i] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2[i](x[i]), \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv3\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:  \u001b[38;5;66;03m# Training path\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/ultralytics/nn/modules/conv.py:50\u001b[0m, in \u001b[0;36mConv.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     49\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Apply convolution, batch normalization and activation to input tensor.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = YOLO(\"/kaggle/input/meowmeow/last(2)-yolo9.pt\")\n",
    "\n",
    "result = model.train(data=\"/kaggle/working/power.yaml\", \n",
    "    epochs=100,\n",
    "    imgsz=640,\n",
    "    batch=128,\n",
    "    save_period=2,\n",
    "    mixup=0.4, \n",
    "    mosaic=0.6, \n",
    "    dropout=0.2,\n",
    "    optimizer=\"auto\",\n",
    "    name=\"Power Assets with Yolov9\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5316077,
     "sourceId": 8882063,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5429372,
     "sourceId": 9011323,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
